splitted_dec <- str_split(dec_pdf, " <--NEW URL--> ")[[1]]
## if any has _EN, then the multiple ones are just translated versions, keep the enlgish one.
if(str_detect(splitted_dec, "\\_EN\\.pdf")){
dec_pdf <- splitted_dec[str_detect(splitted_dec, "\\_EN\\.pdf")]
## parse it
parsed_txt <- try(pdf_text(dec_pdf)[-1] %>%
paste(., collapse = "\r\n"), silent = TRUE)
# if couldn't parse it, try ocr
if(class(parsed_txt) == "try-error"){
parsed_txt <- try(tesseract::ocr(dec_pdf) %>%
paste(., collapse = "\r\n"), silent = TRUE)
}
# if yet again it fails, assign NA
if(class(parsed_txt) == "try-error"){
parsed_txt <- NA_character_
}
} else {
##Parse each one individually, and then paste them together.
# container var
container <- rep(NA, length(splitted_dec))
## the loop
for(i in seq_len(length(splitted_dec))){
## parse it
parsed_txt <- try(pdf_text(splitted_dec[i])[-1] %>%
paste(., collapse = "\r\n"), silent = TRUE)
# if couldn't parse it, try ocr
if(class(parsed_txt) == "try-error"){
parsed_txt <- try(tesseract::ocr(splitted_dec[i]) %>%
paste(., collapse = "\r\n"), silent = TRUE)
}
# if yet again it fails, assign NA
if(class(parsed_txt) == "try-error"){
parsed_txt <- NA_character_
}
## assign to the container
container[i] <- parsed_txt
}
## remove NAs, and paste all the versions of the decisions together
parsed_txt <- container %>%
paste(., collapse = " <<--NEW VERSION-->> ")
}
}
} else {
## no decision
parsed_txt <- "no decision text"
}
## print str for double checking
str(parsed_txt, nchar.max = 1000)
## rest time for the server
Sys.sleep(runif(2,1,3))
return(parsed_txt)
})
dec_pdf <- DGComp_data$decision_url[1]
### nto a website, missing the url
if(str_detect(dec_pdf, "europa") == FALSE){
### check if there are more than one urls
if(length(str_split(dec_pdf, " <--NEW URL--> ")[[1]]) < 2){
## parse it
parsed_txt <- try(pdf_text(dec_pdf)[-1] %>%
paste(., collapse = "\r\n"), silent = TRUE)
# if couldn't parse it, try ocr
if(class(parsed_txt) == "try-error"){
parsed_txt <- try(tesseract::ocr(dec_pdf) %>%
paste(., collapse = "\r\n"), silent = TRUE)
}
# if yet again it fails, assign NA
if(class(parsed_txt) == "try-error"){
parsed_txt <- NA_character_
}
} else {
### then it has more than one pdf doc.
## split them apart into a vector
splitted_dec <- str_split(dec_pdf, " <--NEW URL--> ")[[1]]
## if any has _EN, then the multiple ones are just translated versions, keep the enlgish one.
if(str_detect(splitted_dec, "\\_EN\\.pdf")){
dec_pdf <- splitted_dec[str_detect(splitted_dec, "\\_EN\\.pdf")]
## parse it
parsed_txt <- try(pdf_text(dec_pdf)[-1] %>%
paste(., collapse = "\r\n"), silent = TRUE)
# if couldn't parse it, try ocr
if(class(parsed_txt) == "try-error"){
parsed_txt <- try(tesseract::ocr(dec_pdf) %>%
paste(., collapse = "\r\n"), silent = TRUE)
}
# if yet again it fails, assign NA
if(class(parsed_txt) == "try-error"){
parsed_txt <- NA_character_
}
} else {
##Parse each one individually, and then paste them together.
# container var
container <- rep(NA, length(splitted_dec))
## the loop
for(i in seq_len(length(splitted_dec))){
## parse it
parsed_txt <- try(pdf_text(splitted_dec[i])[-1] %>%
paste(., collapse = "\r\n"), silent = TRUE)
# if couldn't parse it, try ocr
if(class(parsed_txt) == "try-error"){
parsed_txt <- try(tesseract::ocr(splitted_dec[i]) %>%
paste(., collapse = "\r\n"), silent = TRUE)
}
# if yet again it fails, assign NA
if(class(parsed_txt) == "try-error"){
parsed_txt <- NA_character_
}
## assign to the container
container[i] <- parsed_txt
}
## remove NAs, and paste all the versions of the decisions together
parsed_txt <- container %>%
paste(., collapse = " <<--NEW VERSION-->> ")
}
}
} else {
## no decision
parsed_txt <- "no decision text"
}
decision_txt <- map2_chr(DGComp_data$decision_url, DGComp_data$case_id, function(dec_pdf, id){
print(paste0("parsing case: ", id))
### nto a website, missing the url
if(str_detect(dec_pdf, "europa")){
### check if there are more than one urls
if(length(str_split(dec_pdf, " <--NEW URL--> ")[[1]]) < 2){
## parse it
parsed_txt <- try(pdf_text(dec_pdf)[-1] %>%
paste(., collapse = "\r\n"), silent = TRUE)
# if couldn't parse it, try ocr
if(class(parsed_txt) == "try-error"){
parsed_txt <- try(tesseract::ocr(dec_pdf) %>%
paste(., collapse = "\r\n"), silent = TRUE)
}
# if yet again it fails, assign NA
if(class(parsed_txt) == "try-error"){
parsed_txt <- NA_character_
}
} else {
### then it has more than one pdf doc.
## split them apart into a vector
splitted_dec <- str_split(dec_pdf, " <--NEW URL--> ")[[1]]
## if any has _EN, then the multiple ones are just translated versions, keep the enlgish one.
if(str_detect(splitted_dec, "\\_EN\\.pdf")){
dec_pdf <- splitted_dec[str_detect(splitted_dec, "\\_EN\\.pdf")]
## parse it
parsed_txt <- try(pdf_text(dec_pdf)[-1] %>%
paste(., collapse = "\r\n"), silent = TRUE)
# if couldn't parse it, try ocr
if(class(parsed_txt) == "try-error"){
parsed_txt <- try(tesseract::ocr(dec_pdf) %>%
paste(., collapse = "\r\n"), silent = TRUE)
}
# if yet again it fails, assign NA
if(class(parsed_txt) == "try-error"){
parsed_txt <- NA_character_
}
} else {
##Parse each one individually, and then paste them together.
# container var
container <- rep(NA, length(splitted_dec))
## the loop
for(i in seq_len(length(splitted_dec))){
## parse it
parsed_txt <- try(pdf_text(splitted_dec[i])[-1] %>%
paste(., collapse = "\r\n"), silent = TRUE)
# if couldn't parse it, try ocr
if(class(parsed_txt) == "try-error"){
parsed_txt <- try(tesseract::ocr(splitted_dec[i]) %>%
paste(., collapse = "\r\n"), silent = TRUE)
}
# if yet again it fails, assign NA
if(class(parsed_txt) == "try-error"){
parsed_txt <- NA_character_
}
## assign to the container
container[i] <- parsed_txt
}
## remove NAs, and paste all the versions of the decisions together
parsed_txt <- container %>%
paste(., collapse = " <<--NEW VERSION-->> ")
}
}
} else {
## no decision
parsed_txt <- "no decision text"
}
## print str for double checking
str(parsed_txt, nchar.max = 1000)
## rest time for the server
Sys.sleep(runif(2,1,3))
return(parsed_txt)
})
View(DGComp_data)
dec_pdf <- NA
!is.na(dec_pdf) & str_detect(dec_pdf, "europa")
decision_txt <- map2_chr(DGComp_data$decision_url, DGComp_data$case_id, function(dec_pdf, id){
print(paste0("parsing case: ", id))
### nto a website, missing the url
if(!is.na(dec_pdf) & str_detect(dec_pdf, "europa")){
### check if there are more than one urls
if(length(str_split(dec_pdf, " <--NEW URL--> ")[[1]]) < 2){
## parse it
parsed_txt <- try(pdf_text(dec_pdf)[-1] %>%
paste(., collapse = "\r\n"), silent = TRUE)
# if couldn't parse it, try ocr
if(class(parsed_txt) == "try-error"){
parsed_txt <- try(tesseract::ocr(dec_pdf) %>%
paste(., collapse = "\r\n"), silent = TRUE)
}
# if yet again it fails, assign NA
if(class(parsed_txt) == "try-error"){
parsed_txt <- NA_character_
}
} else {
### then it has more than one pdf doc.
## split them apart into a vector
splitted_dec <- str_split(dec_pdf, " <--NEW URL--> ")[[1]]
## if any has _EN, then the multiple ones are just translated versions, keep the enlgish one.
if(str_detect(splitted_dec, "\\_EN\\.pdf")){
dec_pdf <- splitted_dec[str_detect(splitted_dec, "\\_EN\\.pdf")]
## parse it
parsed_txt <- try(pdf_text(dec_pdf)[-1] %>%
paste(., collapse = "\r\n"), silent = TRUE)
# if couldn't parse it, try ocr
if(class(parsed_txt) == "try-error"){
parsed_txt <- try(tesseract::ocr(dec_pdf) %>%
paste(., collapse = "\r\n"), silent = TRUE)
}
# if yet again it fails, assign NA
if(class(parsed_txt) == "try-error"){
parsed_txt <- NA_character_
}
} else {
##Parse each one individually, and then paste them together.
# container var
container <- rep(NA, length(splitted_dec))
## the loop
for(i in seq_len(length(splitted_dec))){
## parse it
parsed_txt <- try(pdf_text(splitted_dec[i])[-1] %>%
paste(., collapse = "\r\n"), silent = TRUE)
# if couldn't parse it, try ocr
if(class(parsed_txt) == "try-error"){
parsed_txt <- try(tesseract::ocr(splitted_dec[i]) %>%
paste(., collapse = "\r\n"), silent = TRUE)
}
# if yet again it fails, assign NA
if(class(parsed_txt) == "try-error"){
parsed_txt <- NA_character_
}
## assign to the container
container[i] <- parsed_txt
}
## remove NAs, and paste all the versions of the decisions together
parsed_txt <- container %>%
paste(., collapse = " <<--NEW VERSION-->> ")
}
}
} else {
## no decision
parsed_txt <- "no decision text"
}
## print str for double checking
str(parsed_txt, nchar.max = 1000)
## rest time for the server
Sys.sleep(runif(2,1,3))
return(parsed_txt)
})
q()
## Load the relevant packages
require(tidyverse)
require(rvest)
require(xlsx)
require(pdftools)
decision_txt <- map2_chr(DGComp_data$decision_url, DGComp_data$case_id, function(dec_pdf, id){
print(paste0("parsing case: ", id))
### nto a website, missing the url
if(!is.na(dec_pdf) & str_detect(dec_pdf, "europa")){
### check if there are more than one urls
if(length(str_split(dec_pdf, " <--NEW URL--> ")[[1]]) < 2){
## parse it
parsed_txt <- try(pdf_text(dec_pdf)[-1] %>%
paste(., collapse = "\r\n"), silent = TRUE)
# if couldn't parse it, try ocr
if(class(parsed_txt) == "try-error"){
parsed_txt <- try(tesseract::ocr(dec_pdf) %>%
paste(., collapse = "\r\n"), silent = TRUE)
}
# if yet again it fails, assign NA
if(class(parsed_txt) == "try-error"){
parsed_txt <- NA_character_
}
} else {
### then it has more than one pdf doc.
## split them apart into a vector
splitted_dec <- str_split(dec_pdf, " <--NEW URL--> ")[[1]]
## if any has _EN, then the multiple ones are just translated versions, keep the enlgish one.
if(str_detect(splitted_dec, "\\_EN\\.pdf")){
dec_pdf <- splitted_dec[str_detect(splitted_dec, "\\_EN\\.pdf")]
## parse it
parsed_txt <- try(pdf_text(dec_pdf)[-1] %>%
paste(., collapse = "\r\n"), silent = TRUE)
# if couldn't parse it, try ocr
if(class(parsed_txt) == "try-error"){
parsed_txt <- try(tesseract::ocr(dec_pdf) %>%
paste(., collapse = "\r\n"), silent = TRUE)
}
# if yet again it fails, assign NA
if(class(parsed_txt) == "try-error"){
parsed_txt <- NA_character_
}
} else {
##Parse each one individually, and then paste them together.
# container var
container <- rep(NA, length(splitted_dec))
## the loop
for(i in seq_len(length(splitted_dec))){
## parse it
parsed_txt <- try(pdf_text(splitted_dec[i])[-1] %>%
paste(., collapse = "\r\n"), silent = TRUE)
# if couldn't parse it, try ocr
if(class(parsed_txt) == "try-error"){
parsed_txt <- try(tesseract::ocr(splitted_dec[i]) %>%
paste(., collapse = "\r\n"), silent = TRUE)
}
# if yet again it fails, assign NA
if(class(parsed_txt) == "try-error"){
parsed_txt <- NA_character_
}
## assign to the container
container[i] <- parsed_txt
}
## remove NAs, and paste all the versions of the decisions together
parsed_txt <- container %>%
paste(., collapse = " <<--NEW VERSION-->> ")
}
}
} else {
## no decision
parsed_txt <- "no decision text"
}
## print str for double checking
str(parsed_txt, nchar.max = 1000)
## rest time for the server
Sys.sleep(runif(2,1,3))
return(parsed_txt)
})
### Assign it to the dataset and save it
DGComp_data$decision_txt <- decision_txt
head(DGComp_data$decision_txt)
head(DGComp_data$decision_txt)
head(DGComp_data$decision_txt)
### export it
save(DGComp_data,
file = paste0("data_repo/DGcomp/2_", str_extract(Sys.time(), "^.*?(?=\\s)"), "_","dgComp_NACE_K_ALL_mergerCases.Rdata"))
write.xlsx(DGComp_data,
file = paste0("data_repo/DGcomp/2_", str_extract(Sys.time(), "^.*?(?=\\s)"), "_","dgComp_NACE_K_ALL_mergerCases.xlsx"))
?file.remove
list.files()
list.files()[str_detect(list.files(), regex("\\.png", ignore_case = TRUE))]
### remove all the ocr pages
file.remove(list.files()[str_detect(list.files(), regex("\\.png", ignore_case = TRUE))])
### Save each decision as a .txt file
## decision_repo
if(!dir.exists("data_repo/DGcomp/decision_repo")){
dir.create("data_repo/DGcomp/decision_repo")
}
## write them and save them
map2(DGComp_data$case_id, DGComp_data$decision_txt, function(id, txt) cat(txt,
file = paste0("data_repo/DGcomp/decision_repo", id, ".txt")) )
id <- 1
paste0("data_repo/DGcomp/decision_repo", id, ".txt")
## write them and save them
map2(DGComp_data$case_id, DGComp_data$decision_txt, function(id, txt) cat(txt,
file = paste0("data_repo/DGcomp/decision_repo/", id, ".txt")) )
require(cld3)
### first filtering, get all the decisions written in Germna
DGComp_data <- DGComp_data %>%
mutate(decision_lang = cld3::detect_language(decision_txt))
table(DGComp_data$decision_lang)
str_detect(DGComp_data$decision_txt, regex(retail, ignore_case = TRUE))
str_detect(DGComp_data$decision_txt, regex("retail", ignore_case = TRUE))
DGComp_data$case_id[str_detect(DGComp_data$decision_txt, regex("retail", ignore_case = TRUE))]
DGComp_data$case_id[str_detect(DGComp_data$decision_txt, regex("retail.*bank", ignore_case = TRUE))]
DGComp_data$case_id[str_detect(DGComp_data$decision_txt, regex("retail.*bank.*german(y)?", ignore_case = TRUE))]
DGComp_data$case_id[str_detect(DGComp_data$decision_txt, regex("retail.*bank.*german", ignore_case = TRUE))]
DGComp_data %>% filter(str_detect(decision_txt, regex("germany", ignore_case = TRUE)))
DGComp_data %>% filter(str_detect(decision_txt, regex("germany", ignore_case = TRUE)) & str_detect(decision_txt, regex("retail", ignore_case = TRUE)))
DGComp_data %>% filter(str_detect(decision_txt, regex("germany", ignore_case = TRUE)) & str_detect(decision_txt, regex("retail", ignore_case = TRUE)) & str_detect(decision_txt, regex("bank", ignore_case = TRUE)))
DGComp_data %>% filter(str_detect(decision_txt, regex("germany", ignore_case = TRUE)) & str_detect(decision_txt, regex("retail", ignore_case = TRUE)) & str_detect(decision_txt, regex("bank", ignore_case = TRUE))) %>% View()
DGComp_data %>% filter((str_detect(decision_txt, regex("germany", ignore_case = TRUE)) & str_detect(decision_txt, regex("retail", ignore_case = TRUE)) & str_detect(decision_txt, regex("bank", ignore_case = TRUE))) | decision_lang == "de") %>% View()
DGComp_data %>% filter((str_detect(decision_txt, regex("germany", ignore_case = TRUE)) & str_detect(decision_txt, regex("retail", ignore_case = TRUE)) & str_detect(decision_txt, regex("bank", ignore_case = TRUE))) | decision_lang == "de")
DGComp_filtered <- DGComp_data %>%
filter((str_detect(decision_txt, regex("germany", ignore_case = TRUE)) & str_detect(decision_txt, regex("retail", ignore_case = TRUE)) & str_detect(decision_txt, regex("bank", ignore_case = TRUE))) | decision_lang == "de")
save(DGComp_data,
file = paste0("data_repo/DGcomp/3_", str_extract(Sys.time(), "^.*?(?=\\s)"), "_","dgComp_filteredGermanRetailBank_mergerCases.Rdata"))
write.xlsx(DGComp_data,
file = paste0("data_repo/DGcomp/3_", str_extract(Sys.time(), "^.*?(?=\\s)"), "_","dgComp_filteredGermanRetailBank_mergerCases.xlsx"))
DGComp_filtered <- DGComp_data %>%
filter((str_detect(decision_txt, regex("german", ignore_case = TRUE)) & str_detect(decision_txt, regex("retail", ignore_case = TRUE)) & str_detect(decision_txt, regex("bank", ignore_case = TRUE))) | decision_lang == "de")
## export
save(DGComp_data,
file = paste0("data_repo/DGcomp/3_", str_extract(Sys.time(), "^.*?(?=\\s)"), "_","dgComp_filteredGermanRetailBank_mergerCases.Rdata"))
write.xlsx(DGComp_data,
file = paste0("data_repo/DGcomp/3_", str_extract(Sys.time(), "^.*?(?=\\s)"), "_","dgComp_filteredGermanRetailBank_mergerCases.xlsx"))
DGComp_filtered <- DGComp_data %>%
filter((str_detect(decision_txt, regex("german", ignore_case = TRUE)) & str_detect(decision_txt, regex("retail", ignore_case = TRUE)) & str_detect(decision_txt, regex("bank", ignore_case = TRUE))) | (decision_lang == "de" & str_detect(decision_txt, "no decision") == FALSE))
DGComp_filtered <- DGComp_data %>%
filter((str_detect(decision_txt, regex("german", ignore_case = TRUE)) & str_detect(decision_txt, regex("retail", ignore_case = TRUE)) & str_detect(decision_txt, regex("bank", ignore_case = TRUE))) | (str_detect(decision_txt, "no decision") == FALSE) & decision_lang == "de")
DGComp_filtered <- DGComp_data %>%
filter((str_detect(decision_txt, regex("german", ignore_case = TRUE)) & str_detect(decision_txt, regex("retail", ignore_case = TRUE)) & str_detect(decision_txt, regex("bank", ignore_case = TRUE))) | (str_detect(decision_txt, "no decision") == FALSE & decision_lang == "de"))
DGComp_filtered <- DGComp_data %>%
filter((str_detect(decision_txt, regex("german", ignore_case = TRUE)) & str_detect(decision_txt, regex("retail", ignore_case = TRUE)) & str_detect(decision_txt, regex("bank", ignore_case = TRUE))) | (decision_lang == "de"))
DGComp_filtered <- DGComp_data %>%
filter((str_detect(decision_txt, regex("german", ignore_case = TRUE)) & str_detect(decision_txt, regex("retail", ignore_case = TRUE)) & str_detect(decision_txt, regex("bank", ignore_case = TRUE))) | (str_detect(decision_txt, "no decision") == FALSE & decision_lang == "de"))
## export
save(DGComp_data,
file = paste0("data_repo/DGcomp/3_", str_extract(Sys.time(), "^.*?(?=\\s)"), "_","dgComp_filteredGermanRetailBank_mergerCases.Rdata"))
write.xlsx(DGComp_data,
file = paste0("data_repo/DGcomp/3_", str_extract(Sys.time(), "^.*?(?=\\s)"), "_","dgComp_filteredGermanRetailBank_mergerCases.xlsx"))
save(DGComp_filtered,
file = paste0("data_repo/DGcomp/3_", str_extract(Sys.time(), "^.*?(?=\\s)"), "_","dgComp_filteredGermanRetailBank_mergerCases.Rdata"))
write.xlsx(DGComp_filtered,
file = paste0("data_repo/DGcomp/3_", str_extract(Sys.time(), "^.*?(?=\\s)"), "_","dgComp_filteredGermanRetailBank_mergerCases.xlsx"))
q()
require(tidyverse)
require(rvest)
require(xlsx)
require(pdftools)
DGComp_data %>%
filter((str_detect(decision_txt, regex("german", ignore_case = TRUE)) & str_detect(decision_txt, regex("bank", ignore_case = TRUE))) | (str_detect(decision_txt, "no decision") == FALSE & decision_lang == "de"))
DGComp_filtered <- DGComp_data %>%
filter((str_detect(decision_txt, regex("german", ignore_case = TRUE)) & str_detect(decision_txt, regex("bank", ignore_case = TRUE))) | (str_detect(decision_txt, "no decision") == FALSE & decision_lang == "de"))
save(DGComp_filtered,
file = paste0("data_repo/DGcomp/3_", str_extract(Sys.time(), "^.*?(?=\\s)"), "_","dgComp_filteredGermanRetailBank_mergerCases.Rdata"))
write.xlsx(DGComp_filtered,
file = paste0("data_repo/DGcomp/3_", str_extract(Sys.time(), "^.*?(?=\\s)"), "_","dgComp_filteredGermanRetailBank_mergerCases.xlsx"))
View(cases_table)
coded <- read.xlsx(file = "data_repo/DGcomp/coded.xlsx")
coded <- read.xlsx(file = "data_repo/DGcomp/4_2018-12-30_dgComp_handCodedRelevantMergerCases.xlsx",
sheetName = "Sheet1")
View(coded)
setdiff(names(coded), nmes(DGComp_filtered))
setdiff(names(coded), names(DGComp_filtered))
coded <- read.xlsx(file = "data_repo/DGcomp/4_2018-12-30_dgComp_handCodedRelevantMergerCases.xlsx",
sheetName = "Sheet1") %>%
select(-row_number)
setdiff(names(coded), names(DGComp_filtered))
DGComp_filtered <- mutate(DGComp_filtered, hc_finished = NA_character_;
relevant = NA_character_)
DGComp_filtered <- mutate(DGComp_filtered, hc_finished = NA_character_,
relevant = NA_character_)
left_join(DGComp_filtered, coded)
DGComp_filtered <- mutate(DGComp_filtered, hc_finished = NA,
relevant = NA)
left_join(DGComp_filtered, coded)
left_join(DGComp_filtered, coded) %>%
select(hc_finished, everything())
left_join(DGComp_filtered, coded) %>%
select(hc_finished, everything()) %>%
View()
DGComp_filtered <- DGComp_data %>%
filter((str_detect(decision_txt, regex("german|deutsch", ignore_case = TRUE)) & str_detect(decision_txt, regex("bank", ignore_case = TRUE))) | (str_detect(decision_txt, "no decision") == FALSE & decision_lang == "de"))
DGComp_filtered <- DGComp_data %>%
filter((str_detect(decision_txt, regex("german|deutsch", ignore_case = TRUE)) | (str_detect(decision_txt, "no decision") == FALSE & decision_lang == "de")))
### Second method of filtering, we extract all decisions which mention germany or which are in german.
DGComp_filtered <- DGComp_data %>%
filter((str_detect(decision_txt, regex("german|deutsch", ignore_case = TRUE)) | (str_detect(decision_txt, "no decision") == FALSE & decision_lang == "de")))
## export
save(DGComp_filtered,
file = paste0("data_repo/DGcomp/3_", str_extract(Sys.time(), "^.*?(?=\\s)"), "_","dgComp_filteredGermanRetailBank_mergerCases.Rdata"))
write.xlsx(DGComp_filtered,
file = paste0("data_repo/DGcomp/3_", str_extract(Sys.time(), "^.*?(?=\\s)"), "_","dgComp_filteredGermanRetailBank_mergerCases.xlsx"))
right_join(DGComp_filtered, coded) %>%
select(hc_finished, everything()) %>%
View()
t <- full_join(DGComp_filtered, coded) %>%
select(hc_finished, everything()) %>%
View()
t <- full_join(DGComp_filtered, coded) %>%
select(hc_finished, everything())
?left_join
t <- left_join(DGComp_filtered, coded) %>%
select(hc_finished, everything())
table(t$hc_finished)
table(coded$hc_finished)
t <- left_join(DGComp_filtered, coded) %>%
select(hc_finished, everything())
table(t$hc_finished)
DGComp_filtered <- mutate(DGComp_filtered, hc_finished = NA,
relevant = NA)
t <- left_join(coded, DGComp_filtered)
table(t$hc_finished)
t <- right_join(coded, DGComp_filtered)
table(t$hc_finished)
t <- right_join(DGComp_filtered, coded)
t <- left_join(DGComp_filtered, coded)
table(t$hc_finished)
t <- DGComp_filtered
t$hc_finished <- coded$hc_finished[match(t$case_id, coded$case_id)]
table(t$hc_finished, useNA = "always")
View(t)
t$hc_finished[t$case_id == "M.8553"]
t$hc_finished[t$case_id == "M.875"]
names(t)
t$relevant <- coded$relevant[match(t$case_id, coded$case_id)]
t <- select(t, hc_finished, everything())
write.xlsx(DGComp_filtered,
file = paste0("data_repo/DGcomp/4_", str_extract(Sys.time(), "^.*?(?=\\s)"), "_","dgComp_handcodedRelevantMergerCases.xlsx"))
DGComp_filtered <- t
write.xlsx(DGComp_filtered,
file = paste0("data_repo/DGcomp/4_", str_extract(Sys.time(), "^.*?(?=\\s)"), "_","dgComp_handcodedMergerCases.xlsx"))
q()
