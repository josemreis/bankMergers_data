read_html() %>%
html_node("#searchResultTable") %>%
html_table() %>%
as_tibble() %>% pull(2)
page %>%
read_html() %>%
html_node("#searchResultTable") %>%
html_table() %>%
as_tibble() %>% str_replace_all(2, "&shy;") %>% pull(2)
page %>%
read_html() %>%
html_node("#searchResultTable") %>%
html_table() %>%
as_tibble() %>% str_replace_all(Kurzbetreff, "&shy;") %>% pull(2)
page %>%
read_html() %>%
html_node("#searchResultTable") %>%
html_table() %>%
as_tibble() %>% str_replace_all(Kurzbetreff, "&shy;", "") %>% pull(2)
page %>%
read_html() %>%
html_node("#searchResultTable") %>%
html_table() %>%
as_tibble() %>% mutate(Kurzbetreff = str_replace_all(Kurzbetreff, "\\&shy\\;", "") %>% pull(2)
page %>%
read_html() %>%
html_node("#searchResultTable") %>%
html_table() %>%
as_tibble() %>% mutate(Kurzbetreff = str_replace_all(Kurzbetreff, "\\&shy\\;", "")) %>% pull(2)
page %>%
read_html() %>%
html_node("#searchResultTable") %>%
html_table() %>%
as_tibble() %>% mutate(Kurzbetreff = str_replace_all(Kurzbetreff, "\\&shy\\;", "")) %>% pull(2)
str_detect("GU Has­pa Fi­nanz­hol­ding", "­")
str_remove"GU Has­pa Fi­nanz­hol­ding", "­")
str_remove("GU Has­pa Fi­nanz­hol­ding", "­")
str_remove_all("GU Has­pa Fi­nanz­hol­ding", "­")
### remove some hidden html entities
t <- bka_data %>%
mutate_all(is.character, str_remove_all, "­")
?mutate_all
### remove some hidden html entities
t <- bka_data %>%
mutate_all(str_remove_all, "­")
View(t)
str_remove("11
GU Has­pa Fi­nanz­hol­ding / Kreiss­par­kas­se Her­zog­tum Lau­e", "­")
str_remove("U Has­pa Fi­nanz­hol­ding / Kreiss­par­kas­se Her­zog­tum Lau­e", "­")
str_remove_all("U Has­pa Fi­nanz­hol­ding / Kreiss­par­kas­se Her­zog­tum Lau­e", "­")
### remove some hidden html entities
t <- bka_data %>%
mutate_all(funs(str_remove_all(., "­")))
View(t)
str_extract("GU Has­pa Fi­nanz­hol­ding", "[[:alpha:]]+|[[:punct:]](?![[:digit::]])")
str_extract_all("GU Has­pa Fi­nanz­hol­ding", "[[:alpha:]]+|[[:punct:]](?![[:digit::]])")
htmlentities
require(htmltools)
htmlEscape("GU Has­pa Fi­nanz­hol­ding /")
htmlEscape("GU Has­pa Fi­nanz­hol­ding /", "--")
htmlEscape("GU Has­pa Fi­nanz­hol­ding /", attribute = TRUE)
xml2::unescape_html("&euro; 2.99")
read_html("<x>fus&shy;</x>")
read_html("<x>fus&shy;ion</x>")
read_html("<x>GU Has­pa Fi­nanz­hol­ding /</x>")
str_remove_all("GU Has­pa Fi­nanz­hol­ding ", "­")
t <- "GU Has­pa Fi­nanz­hol­ding "
t
t
t <- "me­di­en hol­ding: nord GmbH / Axel Sprin­ger AG"
t <- bka_data[6,]
t <- bka_data[6,2]
t <- bka_data$parties[6]
View(t)
str_remove_all(t, "­")
str_remove_all(t, "­") %>% View()
require(textclean)
replace_html(t)
t
replace_html(t) %>% View()
me­di­en hol­ding: nord GmbH /
me­di­en hol­ding: nord GmbH
t
str_remove_all(t, "\U00B7")
str_remove_all("me­di­en hol­ding: nord GmbH / Axel S", "\U00B7")
iconv(t, from = "UTF-8", to = "ASCII", sub = "")
edien holding: nord GmbH /
edien holding: nord GmbH
### remove some hidden html entities
t <- bka_data %>%
mutate_all(funs(iconv(., from = "UTF-8", to = "ASCII", sub = "")))
t$parties[6,1]
t$parties[6]
medien holding: nord GmbH /
load("C:/Dropbox/lexidale/12_2018_GermanyBankingMergers/research_repo/bankingMergers_data/data_repo/germany/2_2018-12-31_germany_merger_cases.Rdata")
### remove some hidden html entities
bka_data  <- bka_data %>%
mutate_all(funs(iconv(., from = "UTF-8", to = "ASCII", sub = "")))
bka_data %>%
filter(str_detect(product_market, regex("bank|geld|finanz|kredit|Girokonten|kasse" , ignore_case = TRUE)) | str_detect(parties, regex("bank|geld|finanz|kredit|Girokonten|kasse" , ignore_case = TRUE))) %>%
mutate(hc_finished = NA,
relevant = NA) %>%
select(hc_finished, everything())
save(bka_data,
file = paste0("data_repo/germany/2_", str_extract(Sys.time(), "^.*?(?=\\s)"), "_","germany_merger_cases.Rdata"))
write.xlsx(bka_data,
file = paste0("data_repo/germany/2_", str_extract(Sys.time(), "^.*?(?=\\s)"), "_","germany_merger_cases.xlsx"))
write.csv(bka_data,
file = paste0("data_repo/germany/2_", str_extract(Sys.time(), "^.*?(?=\\s)"), "_","germany_merger_cases.csv"))
bka_filtered <- bka_data %>%
filter(str_detect(product_market, regex("bank|geld|finanz|kredit|Girokonten|kasse" , ignore_case = TRUE)) | str_detect(parties, regex("bank|geld|finanz|kredit|Girokonten|kasse" , ignore_case = TRUE))) %>%
mutate(hc_finished = NA,
relevant = NA) %>%
select(hc_finished, everything())
save(bka_filtered,
file = paste0("data_repo/germany/3_", str_extract(Sys.time(), "^.*?(?=\\s)"), "_","germany_filtered_mergerCases.Rdata"))
write.xlsx(bka_filtered,
file = paste0("data_repo/germany/3_", str_extract(Sys.time(), "^.*?(?=\\s)"), "_","germany_filtered_mergerCases.xlsx"))
write.csv(bka_filtered,
file = paste0("data_repo/germany/3_", str_extract(Sys.time(), "^.*?(?=\\s)"), "_","germany_filtered_mergerCases.csv"))
load("C:/Dropbox/lexidale/12_2018_GermanyBankingMergers/research_repo/bankingMergers_data/data_repo/germany/2_2018-12-31_germany_merger_cases.Rdata")
### remove some hidden html entities
bka_data  <- bka_data %>%
mutate(parties = iconv(parties, from = "UTF-8", to = "ASCII", sub = ""),
product_market = iconv(product_market, from = "UTF-8", to = "ASCII", sub = ""))
save(bka_data,
file = paste0("data_repo/germany/2_", str_extract(Sys.time(), "^.*?(?=\\s)"), "_","germany_merger_cases.Rdata"))
write.xlsx(bka_data,
file = paste0("data_repo/germany/2_", str_extract(Sys.time(), "^.*?(?=\\s)"), "_","germany_merger_cases.xlsx"))
write.csv(bka_data,
file = paste0("data_repo/germany/2_", str_extract(Sys.time(), "^.*?(?=\\s)"), "_","germany_merger_cases.csv"))
write.xlsx(bka_data,
file = paste0("data_repo/germany/2_", str_extract(Sys.time(), "^.*?(?=\\s)"), "_","germany_merger_cases.xlsx"))
### remove some hidden html entities
bka_data  <- bka_data %>%
mutate(parties = iconv(parties, from = "UTF-8", to = "ASCII", sub = ""),
product_market = iconv(product_market, from = "UTF-8", to = "ASCII", sub = ""),
decision = iconv(decision, from = "UTF-8", to = "ASCII", sub = ""))
save(bka_data,
file = paste0("data_repo/germany/2_", str_extract(Sys.time(), "^.*?(?=\\s)"), "_","germany_merger_cases.Rdata"))
write.xlsx(bka_data,
file = paste0("data_repo/germany/2_", str_extract(Sys.time(), "^.*?(?=\\s)"), "_","germany_merger_cases.xlsx"))
write.csv(bka_data,
file = paste0("data_repo/germany/2_", str_extract(Sys.time(), "^.*?(?=\\s)"), "_","germany_merger_cases.csv"))
write.xlsx(bka_data,
file = paste0("data_repo/germany/2_", str_extract(Sys.time(), "^.*?(?=\\s)"), "_","germany_merger_cases.xlsx"))
write.xlsx(bka_data,
file = paste0("data_repo/germany/2_", str_extract(Sys.time(), "^.*?(?=\\s)"), "_","germany_merger_cases.xlsx"))
options(java.parameters = "- Xmx1024m")
write.xlsx(bka_data,
file = paste0("data_repo/germany/2_", str_extract(Sys.time(), "^.*?(?=\\s)"), "_","germany_merger_cases.xlsx"))
openxlsx::write.xlsx(bka_data,
file = paste0("data_repo/germany/2_", str_extract(Sys.time(), "^.*?(?=\\s)"), "_","germany_merger_cases.xlsx"))
xlsx::write.xlsx(bka_data,
file = paste0("data_repo/germany/2_", str_extract(Sys.time(), "^.*?(?=\\s)"), "_","germany_merger_cases.xlsx"))
save(bka_filtered,
file = paste0("data_repo/germany/3_", str_extract(Sys.time(), "^.*?(?=\\s)"), "_","germany_filtered_mergerCases.Rdata"))
write.xlsx(bka_filtered,
file = paste0("data_repo/germany/3_", str_extract(Sys.time(), "^.*?(?=\\s)"), "_","germany_filtered_mergerCases.xlsx"))
write.csv(bka_filtered,
file = paste0("data_repo/germany/3_", str_extract(Sys.time(), "^.*?(?=\\s)"), "_","germany_filtered_mergerCases.csv"))
table(bka_filtered$case_id)
### just regex matching using the product market variable
bka_filtered <- bka_data %>%
filter(str_detect(product_market, regex("bank|geld|finanz|kredit|Girokonten|kasse" , ignore_case = TRUE)) | str_detect(parties, regex("bank|geld|finanz|kredit|Girokonten|kasse" , ignore_case = TRUE))) %>%
mutate(hc_finished = NA,
relevant = NA) %>%
select(hc_finished, everything())
table(bka_filtered$case_id)
bka_filtered$decision_txt[1]
### export it
save(bka_filtered,
file = paste0("data_repo/germany/3_", str_extract(Sys.time(), "^.*?(?=\\s)"), "_","germany_filtered_mergerCases.Rdata"))
write.xlsx(bka_filtered,
file = paste0("data_repo/germany/3_", str_extract(Sys.time(), "^.*?(?=\\s)"), "_","germany_filtered_mergerCases.xlsx"))
write.csv(bka_filtered,
file = paste0("data_repo/germany/3_", str_extract(Sys.time(), "^.*?(?=\\s)"), "_","germany_filtered_mergerCases.csv"))
### just regex matching using the product market variable
bka_filtered <- bka_data %>%
filter(str_detect(product_market, regex("bank|geld|finanz|kredit|Girokonten|kasse" , ignore_case = TRUE)) | str_detect(parties, regex("bank|geld|finanz|kredit|Girokonten|kasse" , ignore_case = TRUE))) %>%
mutate(hc_finished = NA,
relevant = NA) %>%
select(hc_finished, everything()) %>%
distinct(case_id, .keep_all = TRUE)
save(bka_filtered,
file = paste0("data_repo/germany/3_", str_extract(Sys.time(), "^.*?(?=\\s)"), "_","germany_filtered_mergerCases.Rdata"))
write.xlsx(bka_filtered,
file = paste0("data_repo/germany/3_", str_extract(Sys.time(), "^.*?(?=\\s)"), "_","germany_filtered_mergerCases.xlsx"))
write.csv(bka_filtered,
file = paste0("data_repo/germany/3_", str_extract(Sys.time(), "^.*?(?=\\s)"), "_","germany_filtered_mergerCases.csv"))
### just regex matching using the product market variable
bka_filtered <- bka_data %>%
filter(str_detect(product_market, regex("bank|geld|finanz|kredit|Girokonten|kasse" , ignore_case = TRUE)) | str_detect(parties, regex("bank|geld|finanz|kredit|Girokonten|kasse" , ignore_case = TRUE))) %>%
mutate(hc_finished = NA,
relevant = NA) %>%
select(hc_finished, everything()) %>%
distinct(decision_date, .keep_all = TRUE)
names(bka_filtered)
### just regex matching using the product market variable
bka_filtered <- bka_data %>%
filter(str_detect(product_market, regex("bank|geld|finanz|kredit|Girokonten|kasse" , ignore_case = TRUE)) | str_detect(parties, regex("bank|geld|finanz|kredit|Girokonten|kasse" , ignore_case = TRUE))) %>%
mutate(hc_finished = NA,
relevant = NA) %>%
select(hc_finished, everything()) %>%
distinct(date, .keep_all = TRUE)
### just regex matching using the product market variable
bka_filtered <- bka_data %>%
filter(str_detect(product_market, regex("bank|geld|finanz|kredit|Girokonten|kasse" , ignore_case = TRUE)) | str_detect(parties, regex("bank|geld|finanz|kredit|Girokonten|kasse" , ignore_case = TRUE))) %>%
mutate(hc_finished = NA,
relevant = NA) %>%
select(hc_finished, everything()) %>%
distinct(date, case_id, .keep_all = TRUE)
### just regex matching using the product market variable
bka_filtered <- bka_data %>%
filter(str_detect(product_market, regex("bank|geld|finanz|kredit|Girokonten|kasse" , ignore_case = TRUE)) | str_detect(parties, regex("bank|geld|finanz|kredit|Girokonten|kasse" , ignore_case = TRUE))) %>%
mutate(hc_finished = NA,
relevant = NA) %>%
select(hc_finished, everything()) %>%
distinct(date, .keep_all = TRUE)
save(bka_filtered,
file = paste0("data_repo/germany/3_", str_extract(Sys.time(), "^.*?(?=\\s)"), "_","germany_filtered_mergerCases.Rdata"))
write.xlsx(bka_filtered,
file = paste0("data_repo/germany/3_", str_extract(Sys.time(), "^.*?(?=\\s)"), "_","germany_filtered_mergerCases.xlsx"))
write.csv(bka_filtered,
file = paste0("data_repo/germany/3_", str_extract(Sys.time(), "^.*?(?=\\s)"), "_","germany_filtered_mergerCases.csv"))
bka_data %>%
filter(str_detect(product_market, regex("bank|geld|finanz|kredit|Girokonten|kasse" , ignore_case = TRUE)) | str_detect(parties, regex("bank|geld|finanz|kredit|Girokonten|kasse" , ignore_case = TRUE))) %>%
mutate(hc_finished = NA,
relevant = NA) %>%
select(hc_finished, everything())
rm(list=ls())
require(tidyverse)
require(rvest)
require(xlsx)
require(pdftools)
## data repo
if(!dir.exists("data_repo")){
dir.create("data_repo")
}
# DG Comp repo
if(!dir.exists("data_repo/DGcomp")){
dir.create("data_repo/DGcomp")
}
### load the id's and prepare them for the url
dgcomp_merger <- openxlsx::read.xlsx("data_repo/DGcomp/interm_data/allMergers.xls")
### load the id's and prepare them for the url
dgcomp_merger <- readxl::read_excel("data_repo/DGcomp/interm_data/allMergers.xls")
### load the id's and prepare them for the url
dgcomp_merger <- readxl::read_excel("data_repo/DGcomp/interm_data/allMergers.xls")
require(readxl)
### load the id's and prepare them for the url
dgcomp_merger <- readxl::read_excel(path = "data_repo/DGcomp/interm_data/allMergers.xls")
### load the id's and prepare them for the url
dgcomp_merger <- openxlsx::read.xlsx("data_repo/DGcomp/interm_data/allMergers.xlsx")
### load the id's and prepare them for the url
dgcomp_merger <- readxl::read_excel(path = "data_repo/DGcomp/interm_data/allMergers.xlsx")
### load the id's and prepare them for the url
dgcomp_merger <- XLConnect::loadWorkbook(filename = "data_repo/DGcomp/interm_data/allMergers.xlsx")
### load the id's and prepare them for the url
dgcomp_merger <- XLConnect::loadWorkbook(filename = "data_repo/DGcomp/interm_data/allMergers.xls")
### load the id's and prepare them for the url
dgcomp_merger <- readxl::read_excel(path = "data_repo/DGcomp/interm_data/allMergers.xls")
### load the id's and prepare them for the url
dgcomp_merger <- read.csv(path = "data_repo/DGcomp/interm_data/allMergers.csv")
### load the id's and prepare them for the url
dgcomp_merger <- read.csv("data_repo/DGcomp/interm_data/allMergers.csv")
View(dgcomp_merger)
### load the id's and prepare them for the url
dgcomp_merger <- read.csv("data_repo/DGcomp/interm_data/allMergers.csv") %>%
set_names(names(.) %>%
str_to_lower())
table(dgcomp_merger$nace_code)
### load the id's and prepare them for the url. Its 7352 cases. Keep only the cases relative to financial matters NACE Code "K" as well as those without nace code for hand-coding.
dgcomp_merger <- read.csv("data_repo/DGcomp/interm_data/allMergers.csv") %>%
set_names(names(.) %>%
str_to_lower()) %>%
filter(str_detect(nace_code, "^K") | nchar(nace_code) < 1)
table(dgcomp_merger$nace_code)
sort(table(dgcomp_merger$nace_code))
sort(table(dgcomp_merger$nace_code))
?sort
sort(table(dgcomp_merger$nace_code), decreasing = FALSE)
sort(table(dgcomp_merger$nace_code), decreasing = TRUE)
### load the id's and prepare them for the url. Its 7352 cases. Keep only the cases relative to banking matters, using the relevant NACE Codes as regex "K\\.64(\\s+|\\.1\\s+|\\.9\\s+|\\.2|\\.19\\s+|\\.20\\s+|\\.91\\s+|\\.99\\s+)|K\\.66(\\s+|\\.1\\s+||\\.3)" as well as those without nace code for hand-coding.
dgcomp_merger <- read.csv("data_repo/DGcomp/interm_data/allMergers.csv") %>%
set_names(names(.) %>%
str_to_lower()) %>%
filter(str_detect(nace_code, "K\\.64(\\s+|\\.1\\s+|\\.9\\s+|\\.2|\\.19\\s+|\\.20\\s+|\\.91\\s+|\\.99\\s+)|K\\.66(\\s+|\\.1\\s+||\\.3)") | nchar(nace_code) < 1)
dgcomp_merger %>% filter(nchar(nace_code) < 1)
names(dgcomp_merger)
### load the id's and prepare them for the url. Its 7352 cases. Keep only the cases relative to banking matters, using the relevant NACE Codes as regex "K\\.64(\\s+|\\.1\\s+|\\.9\\s+|\\.2|\\.19\\s+|\\.20\\s+|\\.91\\s+|\\.99\\s+)|K\\.66(\\s+|\\.1\\s+||\\.3)" as well as those without nace code for hand-coding.
dgcomp_merger <- read.csv("data_repo/DGcomp/interm_data/allMergers.csv") %>%
set_names(names(.) %>%
str_to_lower() %>%
str_replace_all("Ã¯\\.+", "")) %>%
filter(str_detect(nace_code, "K\\.64(\\s+|\\.1\\s+|\\.9\\s+|\\.2|\\.19\\s+|\\.20\\s+|\\.91\\s+|\\.99\\s+)|K\\.66(\\s+|\\.1\\s+||\\.3)") | nchar(nace_code) < 1)
case_ids <- str_extract_all(dg_merger$case_code, "(?<=M\\.).*") %>%
str_trim()
case_ids <- str_extract_all(dgcomp_merger$case_code, "(?<=M\\.).*") %>%
str_trim()
case_pages <- paste0("http://ec.europa.eu/competition/elojade/isef/case_details.cfm?proc_code=2_M_", case_ids)
DGComp_cases <- map2_df(case_pages, case_ids, function(page, id){
cat(paste0("scraping case: ", id, "\r\n\r\n"))
### scrape the case table
case_details_table <- page %>%
read_html() %>%
html_nodes(xpath = "//table[@class = 'details']") %>%
html_table() %>%
as.data.frame() %>%
t() %>%
as.data.frame() %>%
set_names(.[1,] %>%
str_replace_all(., "[[:punct:]]", "") %>%
str_to_lower() %>%
str_replace_all(., "\\s+", "_")) %>%
as_tibble() %>%
slice(-1) %>%
mutate(parties = page %>%
read_html() %>%
html_nodes("strong .ClassLink") %>%
html_text() %>%
str_replace_all(., "[[:cntrl:]]", "") %>%
str_trim() %>%
paste(., collapse = "/"),
case_page = page,
case_id = id) %>%
select(case_id, parties, everything())
### scrape the decision_url
decision_url <- try(page %>%
read_html() %>%
html_nodes(xpath = '//a[@class = "ClassLink" and contains(@href, "decisions")]') %>%
html_attr("href"),
silent = TRUE)
## if decisions_url > 1
if(length(decision_url) > 1 & class(decision_url) != "try-error"){
decision_url <- paste(decision_url, collapse = " <--NEW URL--> ")
}
## conditional assignement of the decision url
case_details_table$decision_url <- ifelse(class(decision_url) != "try-error",
decision_url,
NA_character_)
### double checking
print(case_details_table)
print(decision_url)
### rest time for the server
Sys.sleep(runif(2,1,3))
return(case_details_table)
})
View(DGComp_cases)
### Not published cases...
DGComp_cases <- DGComp_cases %>%
mutate(decision_url = replace(decision_url, which(is.na(decision_url)), "not published"))
DGComp_data <- DGComp_cases
save(DGComp_data,
file = paste0("data_repo/DGcomp/", str_extract(Sys.time(), "^.*?(?=\\s)"), "_","dgComp_NACE_K_ALL_mergerCases.Rdata"))
write.xlsx(DGComp_data,
file = paste0("data_repo/DGcomp/", str_extract(Sys.time(), "^.*?(?=\\s)"), "_","dgComp_NACE_K_ALL_mergerCases.xlsx"))
decision_txt <- map2_chr(DGComp_data$decision_url, DGComp_data$case_id, function(dec_pdf, id){
print(paste0("parsing case: ", id))
### nto a website, missing the url
if(!is.na(dec_pdf) & str_detect(dec_pdf, "europa")){
### check if there are more than one urls
if(length(str_split(dec_pdf, " <--NEW URL--> ")[[1]]) < 2){
## parse it
parsed_txt <- try(pdf_text(dec_pdf)[-1] %>%
paste(., collapse = "\r\n"), silent = TRUE)
# if couldn't parse it, try ocr
if(class(parsed_txt) == "try-error"){
parsed_txt <- try(tesseract::ocr(dec_pdf) %>%
paste(., collapse = "\r\n"), silent = TRUE)
}
# if yet again it fails, assign NA
if(class(parsed_txt) == "try-error"){
parsed_txt <- NA_character_
}
} else {
### then it has more than one pdf doc.
## split them apart into a vector
splitted_dec <- str_split(dec_pdf, " <--NEW URL--> ")[[1]]
## if any has _EN, then the multiple ones are just translated versions, keep the enlgish one.
if(str_detect(splitted_dec, "\\_EN\\.pdf")){
dec_pdf <- splitted_dec[str_detect(splitted_dec, "\\_EN\\.pdf")]
## parse it
parsed_txt <- try(pdf_text(dec_pdf)[-1] %>%
paste(., collapse = "\r\n"), silent = TRUE)
# if couldn't parse it, try ocr
if(class(parsed_txt) == "try-error"){
parsed_txt <- try(tesseract::ocr(dec_pdf) %>%
paste(., collapse = "\r\n"), silent = TRUE)
}
# if yet again it fails, assign NA
if(class(parsed_txt) == "try-error"){
parsed_txt <- NA_character_
}
} else {
## Parse each one individually, and then paste them together.
# container var
container <- rep(NA, length(splitted_dec))
## the loop
for(i in seq_len(length(splitted_dec))){
## parse it
parsed_txt <- try(pdf_text(splitted_dec[i])[-1] %>%
paste(., collapse = "\r\n"), silent = TRUE)
# if couldn't parse it, try ocr
if(class(parsed_txt) == "try-error"){
parsed_txt <- try(tesseract::ocr(splitted_dec[i]) %>%
paste(., collapse = "\r\n"), silent = TRUE)
}
# if yet again it fails, assign NA
if(class(parsed_txt) == "try-error"){
parsed_txt <- NA_character_
}
## assign to the container
container[i] <- parsed_txt
}
## remove NAs, and paste all the versions of the decisions together
parsed_txt <- container %>%
paste(., collapse = " <<--NEW VERSION-->> ")
}
}
} else {
## no decision
parsed_txt <- "no decision text"
}
## print str for double checking
str(parsed_txt, nchar.max = 1000)
## rest time for the server
Sys.sleep(runif(2,1,3))
return(parsed_txt)
})
head(decision_txt)
### Assign it to the dataset and save it
DGComp_data$decision_txt <- decision_txt
### remove all the ocr pages
file.remove(list.files()[str_detect(list.files(), regex("\\.png", ignore_case = TRUE))])
### export it
save(DGComp_data,
file = paste0("data_repo/DGcomp/2_", str_extract(Sys.time(), "^.*?(?=\\s)"), "_","dgComp_NACE_K_ALL_mergerCases.Rdata"))
write.xlsx(DGComp_data,
file = paste0("data_repo/DGcomp/2_", str_extract(Sys.time(), "^.*?(?=\\s)"), "_","dgComp_NACE_K_ALL_mergerCases.xlsx"))
if(!dir.exists("data_repo/DGcomp/decision_repo")){
dir.create("data_repo/DGcomp/decision_repo")
}
## write them and save them
map2(DGComp_data$case_id, DGComp_data$decision_txt, function(id, txt) cat(txt,
file = paste0("data_repo/DGcomp/decision_repo/", id, ".txt")))
DGComp_data %>%
filter((str_detect(decision_txt, regex("german|deutsch", ignore_case = TRUE)) | (str_detect(decision_txt, "no decision") == FALSE & decision_lang == "de")))
### first filtering method, get all the decisions written in German. So we code the language of the deciion using cld3::detect_language(decision_txt)
DGComp_data <- DGComp_data %>%
mutate(decision_lang = cld3::detect_language(decision_txt))
DGComp_data %>%
filter((str_detect(decision_txt, regex("german|deutsch", ignore_case = TRUE)) | (str_detect(decision_txt, "no decision") == FALSE & decision_lang == "de")))
library(readxl)
coded <- read_excel("data_repo/DGcomp/4_2018-12-30_dgComp_handcodedMergerCases.xlsx")
View(coded)
names(coded)
select(coded, -"X__1")
names(coded)
setdiff(names(coded), names(DGComp_cases))
setdiff(names(coded), names(DGCompdata))
setdiff(names(coded), names(DGComp_data))
DGComp_data %>%
filter((str_detect(decision_txt, regex("german|deutsch", ignore_case = TRUE)) & str_detect(decision_txt, regex("bank", ignore_case = TRUE))) | (str_detect(decision_txt, "no decision") == FALSE & decision_lang == "de")) %>%
mutate(hc_finished = NA,
relevant = NA)
### Second method of filtering, we extract all decisions which mention germany or which are in german.
DGComp_filtered <- DGComp_data %>%
filter((str_detect(decision_txt, regex("german|deutsch", ignore_case = TRUE)) & str_detect(decision_txt, regex("bank", ignore_case = TRUE))) | (str_detect(decision_txt, "no decision") == FALSE & decision_lang == "de")) %>%
mutate(hc_finished = NA,
relevant = NA)
setdiff(names(coded), names(DGComp_data))
setdiff(names(coded), names(DGComp_filtered))
coded <- select(coded, -"X__1")
setdiff(names(coded), names(DGComp_filtered))
(t <- left_join(DGComp_filtered, coded))
table(t$relevant)
(t <- right_join(DGComp_filtered, coded))
(t <- DGComp_filtered)
t$hc_finished <- coded$hc_finished[match(t$case_id, coded$case_id)]
table(t$relevant)
t$hc_finished <- coded$hc_finished[match(coded$case_id, t$case_id)]
coded$hc_finished[match(t$case_id, coded$case_id)]
table(coded$hc_finished)
match(t$case_id, coded$case_id)
match(coded$case_id, t$case_id)
View(t)
t$case_id
coded$case_id
### Second method of filtering, we extract all decisions which mention germany or which are in german.
DGComp_filtered <- DGComp_data %>%
filter((str_detect(decision_txt, regex("german|deutsch", ignore_case = TRUE)) & str_detect(decision_txt, regex("bank", ignore_case = TRUE))) | (str_detect(decision_txt, "no decision") == FALSE & decision_lang == "de")) %>%
mutate(hc_finished = NA,
relevant = NA,
case_id = paste0("M.", case_id)) %>%
select(hc_finished, everything())
coded$hc_finished[match(t$case_id, coded$case_id)]
(t <- DGComp_filtered)
coded$hc_finished[match(t$case_id, coded$case_id)]
t$hc_finished <- coded$hc_finished[match(t$case_id, coded$case_id)]
t$relevant <- coded$relevant[match(t$case_id, coded$case_id)]
table(t$relevant, useNA = "always")
table(coded$relevant, useNA = "always")
DGComp_filtered$hc_finished <- coded$hc_finished[match(DGComp_filtered$case_id, coded$case_id)]
DGComp_filtered$relevant <- coded$relevant[match(DGComp_filtered$case_id, coded$case_id)]
glimpse(DGComp_filtered)
save(DGComp_filtered,
file = paste0("data_repo/DGcomp/3_", str_extract(Sys.time(), "^.*?(?=\\s)"), "_","dgComp_filteredGermanRetailBank_mergerCases.Rdata"))
write.xlsx(DGComp_filtered,
file = paste0("data_repo/DGcomp/3_", str_extract(Sys.time(), "^.*?(?=\\s)"), "_","dgComp_filteredGermanRetailBank_mergerCases.xlsx"))
rm(list=ls())
q()
