parsed_txt <- "no decision text"
}
dec-p
dec_pdf
length(str_split(dec_pdf, " <--NEW URL--> ")[[1]]) < 2
### check if it is an NA
if(!is.na(dec_pdf)){
### check if there are more than one urls
if(length(str_split(dec_pdf, " <--NEW URL--> ")[[1]]) < 2){
## parse it
parsed_txt <- try(pdf_text(dec_pdf)[-1] %>%
paste(., collapse = "\r\n"), silent = TRUE)
# if couldn't parse it, try ocr
if(class(parsed_txt) == "try-error"){
parsed_txt <- try(tesseract::ocr(dec_pdf) %>%
paste(., collapse = "\r\n"), silent = TRUE)
}
# if yet again it fails, assign NA
if(class(parsed_txt) == "try-error"){
parsed_txt <- NA_character_
}
} else {
### then it has more than one pdf doc.
## split them apart into a vector
splitted_dec <- str_split(dec_pdf, " <--NEW URL--> ")[[1]]
## if any has _EN, then the multiple ones are just translated versions, keep the enlgish one.
if(str_detect(splitted_dec, "\\_EN\\.pdf")){
dec_pdf <- splitted_dec[str_detect(splitted_dec, "\\_EN\\.pdf")]
## parse it
parsed_txt <- try(pdf_text(dec_pdf)[-1] %>%
paste(., collapse = "\r\n"), silent = TRUE)
# if couldn't parse it, try ocr
if(class(parsed_txt) == "try-error"){
parsed_txt <- try(tesseract::ocr(dec_pdf) %>%
paste(., collapse = "\r\n"), silent = TRUE)
}
# if yet again it fails, assign NA
if(class(parsed_txt) == "try-error"){
parsed_txt <- NA_character_
}
} else {
##Parse each one individually, and then paste them together.
# container var
container <- rep(NA, length(splitted_dec))
## the loop
for(i in seq_len(length(splitted_dec))){
## parse it
parsed_txt <- try(pdf_text(splitted_dec[i])[-1] %>%
paste(., collapse = "\r\n"), silent = TRUE)
# if couldn't parse it, try ocr
if(class(parsed_txt) == "try-error"){
parsed_txt <- try(tesseract::ocr(splitted_dec[i]) %>%
paste(., collapse = "\r\n"), silent = TRUE)
}
# if yet again it fails, assign NA
if(class(parsed_txt) == "try-error"){
parsed_txt <- NA_character_
}
## assign to the container
container[i] <- parsed_txt
}
## remove NAs, and paste all the versions of the decisions together
parsed_txt <- container %>%
paste(., collapse = " <<--NEW VERSION-->> ")
}
}
} else {
## no decision
parsed_txt <- "no decision text"
}
parsed_txt
words
str(parsed_txt)
glimpse(parsed_txt)
str
showMethods("str")
words(parsed_txt)
word(parsed_txt, 1, 20)
?str
str(parsed_txt, nchar.max = 500)
str("no decision text", nchar.max = 500)
str(parsed_txt, nchar.max = 1000)
dec_pdf <- NA_character_
DGComp_data$decision_url
dec_pdf <- "nope"
### nto a website, missing the url
if(str_detect(dec_pdf, "europa") == FALSE){
### check if there are more than one urls
if(length(str_split(dec_pdf, " <--NEW URL--> ")[[1]]) < 2){
## parse it
parsed_txt <- try(pdf_text(dec_pdf)[-1] %>%
paste(., collapse = "\r\n"), silent = TRUE)
# if couldn't parse it, try ocr
if(class(parsed_txt) == "try-error"){
parsed_txt <- try(tesseract::ocr(dec_pdf) %>%
paste(., collapse = "\r\n"), silent = TRUE)
}
# if yet again it fails, assign NA
if(class(parsed_txt) == "try-error"){
parsed_txt <- NA_character_
}
} else {
### then it has more than one pdf doc.
## split them apart into a vector
splitted_dec <- str_split(dec_pdf, " <--NEW URL--> ")[[1]]
## if any has _EN, then the multiple ones are just translated versions, keep the enlgish one.
if(str_detect(splitted_dec, "\\_EN\\.pdf")){
dec_pdf <- splitted_dec[str_detect(splitted_dec, "\\_EN\\.pdf")]
## parse it
parsed_txt <- try(pdf_text(dec_pdf)[-1] %>%
paste(., collapse = "\r\n"), silent = TRUE)
# if couldn't parse it, try ocr
if(class(parsed_txt) == "try-error"){
parsed_txt <- try(tesseract::ocr(dec_pdf) %>%
paste(., collapse = "\r\n"), silent = TRUE)
}
# if yet again it fails, assign NA
if(class(parsed_txt) == "try-error"){
parsed_txt <- NA_character_
}
} else {
##Parse each one individually, and then paste them together.
# container var
container <- rep(NA, length(splitted_dec))
## the loop
for(i in seq_len(length(splitted_dec))){
## parse it
parsed_txt <- try(pdf_text(splitted_dec[i])[-1] %>%
paste(., collapse = "\r\n"), silent = TRUE)
# if couldn't parse it, try ocr
if(class(parsed_txt) == "try-error"){
parsed_txt <- try(tesseract::ocr(splitted_dec[i]) %>%
paste(., collapse = "\r\n"), silent = TRUE)
}
# if yet again it fails, assign NA
if(class(parsed_txt) == "try-error"){
parsed_txt <- NA_character_
}
## assign to the container
container[i] <- parsed_txt
}
## remove NAs, and paste all the versions of the decisions together
parsed_txt <- container %>%
paste(., collapse = " <<--NEW VERSION-->> ")
}
}
} else {
## no decision
parsed_txt <- "no decision text"
}
decision_txt <- map2_chr(DGComp_data$decision_url, DGComp_data$case_id, function(dec_pdf, id){
print("parsing case: ", id)
### nto a website, missing the url
if(str_detect(dec_pdf, "europa") == FALSE){
### check if there are more than one urls
if(length(str_split(dec_pdf, " <--NEW URL--> ")[[1]]) < 2){
## parse it
parsed_txt <- try(pdf_text(dec_pdf)[-1] %>%
paste(., collapse = "\r\n"), silent = TRUE)
# if couldn't parse it, try ocr
if(class(parsed_txt) == "try-error"){
parsed_txt <- try(tesseract::ocr(dec_pdf) %>%
paste(., collapse = "\r\n"), silent = TRUE)
}
# if yet again it fails, assign NA
if(class(parsed_txt) == "try-error"){
parsed_txt <- NA_character_
}
} else {
### then it has more than one pdf doc.
## split them apart into a vector
splitted_dec <- str_split(dec_pdf, " <--NEW URL--> ")[[1]]
## if any has _EN, then the multiple ones are just translated versions, keep the enlgish one.
if(str_detect(splitted_dec, "\\_EN\\.pdf")){
dec_pdf <- splitted_dec[str_detect(splitted_dec, "\\_EN\\.pdf")]
## parse it
parsed_txt <- try(pdf_text(dec_pdf)[-1] %>%
paste(., collapse = "\r\n"), silent = TRUE)
# if couldn't parse it, try ocr
if(class(parsed_txt) == "try-error"){
parsed_txt <- try(tesseract::ocr(dec_pdf) %>%
paste(., collapse = "\r\n"), silent = TRUE)
}
# if yet again it fails, assign NA
if(class(parsed_txt) == "try-error"){
parsed_txt <- NA_character_
}
} else {
##Parse each one individually, and then paste them together.
# container var
container <- rep(NA, length(splitted_dec))
## the loop
for(i in seq_len(length(splitted_dec))){
## parse it
parsed_txt <- try(pdf_text(splitted_dec[i])[-1] %>%
paste(., collapse = "\r\n"), silent = TRUE)
# if couldn't parse it, try ocr
if(class(parsed_txt) == "try-error"){
parsed_txt <- try(tesseract::ocr(splitted_dec[i]) %>%
paste(., collapse = "\r\n"), silent = TRUE)
}
# if yet again it fails, assign NA
if(class(parsed_txt) == "try-error"){
parsed_txt <- NA_character_
}
## assign to the container
container[i] <- parsed_txt
}
## remove NAs, and paste all the versions of the decisions together
parsed_txt <- container %>%
paste(., collapse = " <<--NEW VERSION-->> ")
}
}
} else {
## no decision
parsed_txt <- "no decision text"
}
## print str for double checking
str(parsed_txt, nchar.max = 1000)
## rest time for the server
Sys.sleep(runif(2,1,3))
return(parsed_txt)
})
decision_txt <- map2_chr(DGComp_data$decision_url, DGComp_data$case_id, function(dec_pdf, id){
print(paste0("parsing case: ", id))
### nto a website, missing the url
if(str_detect(dec_pdf, "europa") == FALSE){
### check if there are more than one urls
if(length(str_split(dec_pdf, " <--NEW URL--> ")[[1]]) < 2){
## parse it
parsed_txt <- try(pdf_text(dec_pdf)[-1] %>%
paste(., collapse = "\r\n"), silent = TRUE)
# if couldn't parse it, try ocr
if(class(parsed_txt) == "try-error"){
parsed_txt <- try(tesseract::ocr(dec_pdf) %>%
paste(., collapse = "\r\n"), silent = TRUE)
}
# if yet again it fails, assign NA
if(class(parsed_txt) == "try-error"){
parsed_txt <- NA_character_
}
} else {
### then it has more than one pdf doc.
## split them apart into a vector
splitted_dec <- str_split(dec_pdf, " <--NEW URL--> ")[[1]]
## if any has _EN, then the multiple ones are just translated versions, keep the enlgish one.
if(str_detect(splitted_dec, "\\_EN\\.pdf")){
dec_pdf <- splitted_dec[str_detect(splitted_dec, "\\_EN\\.pdf")]
## parse it
parsed_txt <- try(pdf_text(dec_pdf)[-1] %>%
paste(., collapse = "\r\n"), silent = TRUE)
# if couldn't parse it, try ocr
if(class(parsed_txt) == "try-error"){
parsed_txt <- try(tesseract::ocr(dec_pdf) %>%
paste(., collapse = "\r\n"), silent = TRUE)
}
# if yet again it fails, assign NA
if(class(parsed_txt) == "try-error"){
parsed_txt <- NA_character_
}
} else {
##Parse each one individually, and then paste them together.
# container var
container <- rep(NA, length(splitted_dec))
## the loop
for(i in seq_len(length(splitted_dec))){
## parse it
parsed_txt <- try(pdf_text(splitted_dec[i])[-1] %>%
paste(., collapse = "\r\n"), silent = TRUE)
# if couldn't parse it, try ocr
if(class(parsed_txt) == "try-error"){
parsed_txt <- try(tesseract::ocr(splitted_dec[i]) %>%
paste(., collapse = "\r\n"), silent = TRUE)
}
# if yet again it fails, assign NA
if(class(parsed_txt) == "try-error"){
parsed_txt <- NA_character_
}
## assign to the container
container[i] <- parsed_txt
}
## remove NAs, and paste all the versions of the decisions together
parsed_txt <- container %>%
paste(., collapse = " <<--NEW VERSION-->> ")
}
}
} else {
## no decision
parsed_txt <- "no decision text"
}
## print str for double checking
str(parsed_txt, nchar.max = 1000)
## rest time for the server
Sys.sleep(runif(2,1,3))
return(parsed_txt)
})
dec_pdf <- DGComp_data$decision_url[1]
### nto a website, missing the url
if(str_detect(dec_pdf, "europa") == FALSE){
### check if there are more than one urls
if(length(str_split(dec_pdf, " <--NEW URL--> ")[[1]]) < 2){
## parse it
parsed_txt <- try(pdf_text(dec_pdf)[-1] %>%
paste(., collapse = "\r\n"), silent = TRUE)
# if couldn't parse it, try ocr
if(class(parsed_txt) == "try-error"){
parsed_txt <- try(tesseract::ocr(dec_pdf) %>%
paste(., collapse = "\r\n"), silent = TRUE)
}
# if yet again it fails, assign NA
if(class(parsed_txt) == "try-error"){
parsed_txt <- NA_character_
}
} else {
### then it has more than one pdf doc.
## split them apart into a vector
splitted_dec <- str_split(dec_pdf, " <--NEW URL--> ")[[1]]
## if any has _EN, then the multiple ones are just translated versions, keep the enlgish one.
if(str_detect(splitted_dec, "\\_EN\\.pdf")){
dec_pdf <- splitted_dec[str_detect(splitted_dec, "\\_EN\\.pdf")]
## parse it
parsed_txt <- try(pdf_text(dec_pdf)[-1] %>%
paste(., collapse = "\r\n"), silent = TRUE)
# if couldn't parse it, try ocr
if(class(parsed_txt) == "try-error"){
parsed_txt <- try(tesseract::ocr(dec_pdf) %>%
paste(., collapse = "\r\n"), silent = TRUE)
}
# if yet again it fails, assign NA
if(class(parsed_txt) == "try-error"){
parsed_txt <- NA_character_
}
} else {
##Parse each one individually, and then paste them together.
# container var
container <- rep(NA, length(splitted_dec))
## the loop
for(i in seq_len(length(splitted_dec))){
## parse it
parsed_txt <- try(pdf_text(splitted_dec[i])[-1] %>%
paste(., collapse = "\r\n"), silent = TRUE)
# if couldn't parse it, try ocr
if(class(parsed_txt) == "try-error"){
parsed_txt <- try(tesseract::ocr(splitted_dec[i]) %>%
paste(., collapse = "\r\n"), silent = TRUE)
}
# if yet again it fails, assign NA
if(class(parsed_txt) == "try-error"){
parsed_txt <- NA_character_
}
## assign to the container
container[i] <- parsed_txt
}
## remove NAs, and paste all the versions of the decisions together
parsed_txt <- container %>%
paste(., collapse = " <<--NEW VERSION-->> ")
}
}
} else {
## no decision
parsed_txt <- "no decision text"
}
decision_txt <- map2_chr(DGComp_data$decision_url, DGComp_data$case_id, function(dec_pdf, id){
print(paste0("parsing case: ", id))
### nto a website, missing the url
if(str_detect(dec_pdf, "europa")){
### check if there are more than one urls
if(length(str_split(dec_pdf, " <--NEW URL--> ")[[1]]) < 2){
## parse it
parsed_txt <- try(pdf_text(dec_pdf)[-1] %>%
paste(., collapse = "\r\n"), silent = TRUE)
# if couldn't parse it, try ocr
if(class(parsed_txt) == "try-error"){
parsed_txt <- try(tesseract::ocr(dec_pdf) %>%
paste(., collapse = "\r\n"), silent = TRUE)
}
# if yet again it fails, assign NA
if(class(parsed_txt) == "try-error"){
parsed_txt <- NA_character_
}
} else {
### then it has more than one pdf doc.
## split them apart into a vector
splitted_dec <- str_split(dec_pdf, " <--NEW URL--> ")[[1]]
## if any has _EN, then the multiple ones are just translated versions, keep the enlgish one.
if(str_detect(splitted_dec, "\\_EN\\.pdf")){
dec_pdf <- splitted_dec[str_detect(splitted_dec, "\\_EN\\.pdf")]
## parse it
parsed_txt <- try(pdf_text(dec_pdf)[-1] %>%
paste(., collapse = "\r\n"), silent = TRUE)
# if couldn't parse it, try ocr
if(class(parsed_txt) == "try-error"){
parsed_txt <- try(tesseract::ocr(dec_pdf) %>%
paste(., collapse = "\r\n"), silent = TRUE)
}
# if yet again it fails, assign NA
if(class(parsed_txt) == "try-error"){
parsed_txt <- NA_character_
}
} else {
##Parse each one individually, and then paste them together.
# container var
container <- rep(NA, length(splitted_dec))
## the loop
for(i in seq_len(length(splitted_dec))){
## parse it
parsed_txt <- try(pdf_text(splitted_dec[i])[-1] %>%
paste(., collapse = "\r\n"), silent = TRUE)
# if couldn't parse it, try ocr
if(class(parsed_txt) == "try-error"){
parsed_txt <- try(tesseract::ocr(splitted_dec[i]) %>%
paste(., collapse = "\r\n"), silent = TRUE)
}
# if yet again it fails, assign NA
if(class(parsed_txt) == "try-error"){
parsed_txt <- NA_character_
}
## assign to the container
container[i] <- parsed_txt
}
## remove NAs, and paste all the versions of the decisions together
parsed_txt <- container %>%
paste(., collapse = " <<--NEW VERSION-->> ")
}
}
} else {
## no decision
parsed_txt <- "no decision text"
}
## print str for double checking
str(parsed_txt, nchar.max = 1000)
## rest time for the server
Sys.sleep(runif(2,1,3))
return(parsed_txt)
})
View(DGComp_data)
dec_pdf <- NA
!is.na(dec_pdf) & str_detect(dec_pdf, "europa")
decision_txt <- map2_chr(DGComp_data$decision_url, DGComp_data$case_id, function(dec_pdf, id){
print(paste0("parsing case: ", id))
### nto a website, missing the url
if(!is.na(dec_pdf) & str_detect(dec_pdf, "europa")){
### check if there are more than one urls
if(length(str_split(dec_pdf, " <--NEW URL--> ")[[1]]) < 2){
## parse it
parsed_txt <- try(pdf_text(dec_pdf)[-1] %>%
paste(., collapse = "\r\n"), silent = TRUE)
# if couldn't parse it, try ocr
if(class(parsed_txt) == "try-error"){
parsed_txt <- try(tesseract::ocr(dec_pdf) %>%
paste(., collapse = "\r\n"), silent = TRUE)
}
# if yet again it fails, assign NA
if(class(parsed_txt) == "try-error"){
parsed_txt <- NA_character_
}
} else {
### then it has more than one pdf doc.
## split them apart into a vector
splitted_dec <- str_split(dec_pdf, " <--NEW URL--> ")[[1]]
## if any has _EN, then the multiple ones are just translated versions, keep the enlgish one.
if(str_detect(splitted_dec, "\\_EN\\.pdf")){
dec_pdf <- splitted_dec[str_detect(splitted_dec, "\\_EN\\.pdf")]
## parse it
parsed_txt <- try(pdf_text(dec_pdf)[-1] %>%
paste(., collapse = "\r\n"), silent = TRUE)
# if couldn't parse it, try ocr
if(class(parsed_txt) == "try-error"){
parsed_txt <- try(tesseract::ocr(dec_pdf) %>%
paste(., collapse = "\r\n"), silent = TRUE)
}
# if yet again it fails, assign NA
if(class(parsed_txt) == "try-error"){
parsed_txt <- NA_character_
}
} else {
##Parse each one individually, and then paste them together.
# container var
container <- rep(NA, length(splitted_dec))
## the loop
for(i in seq_len(length(splitted_dec))){
## parse it
parsed_txt <- try(pdf_text(splitted_dec[i])[-1] %>%
paste(., collapse = "\r\n"), silent = TRUE)
# if couldn't parse it, try ocr
if(class(parsed_txt) == "try-error"){
parsed_txt <- try(tesseract::ocr(splitted_dec[i]) %>%
paste(., collapse = "\r\n"), silent = TRUE)
}
# if yet again it fails, assign NA
if(class(parsed_txt) == "try-error"){
parsed_txt <- NA_character_
}
## assign to the container
container[i] <- parsed_txt
}
## remove NAs, and paste all the versions of the decisions together
parsed_txt <- container %>%
paste(., collapse = " <<--NEW VERSION-->> ")
}
}
} else {
## no decision
parsed_txt <- "no decision text"
}
## print str for double checking
str(parsed_txt, nchar.max = 1000)
## rest time for the server
Sys.sleep(runif(2,1,3))
return(parsed_txt)
})
q()
